{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20160609_정진하.ipynb","provenance":[{"file_id":"1D5XmduoQ6HDFWCgHqqEgreWAjRvOfcwm","timestamp":1590758618141},{"file_id":"1LYpts1v3YTM8HheW-4YSdJmu8tk2XmZd","timestamp":1590723377075},{"file_id":"1mtf7bW7-9A0t1R0mEjwtAlhk38hQMShy","timestamp":1590487089782}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4SPQIkPmAFD7","colab_type":"text"},"source":["## import modules & set variables"]},{"cell_type":"code","metadata":{"id":"mUC5Vwjz-gCJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593998010329,"user_tz":-540,"elapsed":4544,"user":{"displayName":"Jinha Chung","photoUrl":"","userId":"09027664932398115600"}}},"source":["# for code implementation\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","from google.colab import drive\n","from torch.optim import SGD, Adam\n","from torch.autograd import Variable\n","# for early stopping with IoU metric\n","from sklearn.metrics import jaccard_score\n","# for plotting graphs & data loader\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import Compose, CenterCrop, Normalize\n","from torchvision.transforms import ToTensor, ToPILImage\n","from torchvision.utils import make_grid\n","# others\n","from argparse import ArgumentParser\n","# variables - fixed for VOC2012 data set\n","NUM_CHANNELS = 3\n","NUM_CLASSES = 22"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kw4ooOmgA5Xi","colab_type":"text"},"source":["## mount drive, import custom modules\n","dataset.py, criterion.py, transform.py file from [provided link](https://github.com/bodokaiser/piwise)"]},{"cell_type":"code","metadata":{"id":"IurunKduGedm","colab_type":"code","colab":{}},"source":["# mount your Google Drive\n","drive.flush_and_unmount()\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","# copy source files to this directory, to be able to import it directly\n","# if these files are copied and imported without any error,\n","# mounting is successful\n","!cp \"gdrive/My Drive/Project/dataset.py\" .\n","!cp \"gdrive/My Drive/Project/criterion.py\" .\n","!cp \"gdrive/My Drive/Project/transform.py\" .\n","!cp \"gdrive/My Drive/Project/unet.py\" .\n","from dataset import VOC12\n","from criterion import CrossEntropyLoss2d\n","from transform import Relabel, ToLabel, Colorize, colormap\n","import unet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kdNkm-xFWVlx","colab_type":"text"},"source":["## early stopping metrics\n","stop training early if we reach a certain point either with IoU or dice coefficient"]},{"cell_type":"code","metadata":{"id":"LOaxRQyLWmTi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593998460076,"user_tz":-540,"elapsed":822,"user":{"displayName":"Jinha Chung","photoUrl":"","userId":"09027664932398115600"}}},"source":["def get_iou(labels, target):\n","    # receives 3D tensor (NxHxW) with values as the appropriate label\n","    np_labels = labels.cpu().numpy().reshape(-1)\n","    np_target = target.cpu().numpy().reshape(-1)\n","    # using 'weighted' may take a longer time than others\n","    return jaccard_score(np_target, np_labels, average='weighted')\n","\n","def get_dice():\n","    raise NotImplementedError\n","    return 0\n","\n","def early_stop(use_cuda, output, target, metric, threshold):\n","    '''\n","    output dim: 4x22x256x256\n","    target dim: 4x256x256\n","    given output and target, compute the metric (iou or dice)\n","    and return True if it exceeds the threshold value\n","    '''\n","    if metric == \"iou\":\n","        # output: reduce to 4x256x256 before passing to iou\n","        _, l = torch.max(output, dim=1)\n","        score = get_iou(labels=l, target=target)\n","        print(\"IoU metric score: {}\".format(score))\n","        return (score > threshold)\n","\n","    elif metric == \"dice\":\n","        score = get_dice()\n","        print(\"Dice metric score: {}\".format(score))\n","        return (score > threshold)\n","\n","    print(\"early_stop(): Incorrect metric... returning False by default\")\n","    return False"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yuV-rIlQIKXX","colab_type":"text"},"source":["## training\n","the basic structure of this function is also from [provided link](https://github.com/bodokaiser/piwise)"]},{"cell_type":"code","metadata":{"id":"NGuTCDSyI80v","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593998462305,"user_tz":-540,"elapsed":840,"user":{"displayName":"Jinha Chung","photoUrl":"","userId":"09027664932398115600"}}},"source":["color_transform = Colorize()\n","image_transform = ToPILImage()\n","input_transform = Compose([\n","    CenterCrop(256), # 256x256 cropped image\n","    ToTensor(),\n","    Normalize([.485, .456, .406], [.229, .224, .225]), # mean, std for each channels\n","])\n","\n","target_transform = Compose([\n","    CenterCrop(256), # 256x256 cropped image\n","    ToLabel(),\n","    Relabel(255, 21),\n","])\n","# target_transform = Compose([\n","#     CenterCrop(256),\n","#     ToTensor(),\n","#     Normalize((0),(1/256))\n","# ])\n","cmap = colormap(NUM_CLASSES)[:, np.newaxis, :]\n","\n","def train(args, model):\n","    # set model to training mode\n","    model.train()\n","    # prepare criterion\n","    weight = torch.ones(22)\n","    weight[0] = 0\n","    # load data - even though Python notebook doesn't really support CLI arguments,\n","    # attributes in args will be assigned manually when calling main() function\n","    # previously, this was loading a big chunk.. we now divide into training set\n","    # and validation set\n","    train_loader = DataLoader(\n","                            VOC12(root=args.datadir, train=True, input_transform=input_transform,\n","                                  target_transform=target_transform),\n","                            num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)\n","    val_loader = DataLoader(\n","                            VOC12(root=args.datadir, train=False,input_transform=input_transform,\n","                                  target_transform=target_transform),\n","                            num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)\n","    # use Adam optimizer\n","    optimizer = Adam(model.parameters())\n","    # for loss calculation, we still use CrossEntropyLoss\n","    if args.cuda:\n","        criterion = CrossEntropyLoss2d(weight.cuda())\n","    else:\n","        criterion = CrossEntropyLoss2d(weight)\n","    # start training - epoch values start from 1 to make numbers look 'pretty'\n","    for epoch in range(1, args.num_epochs + 1):\n","        epoch_loss = []\n","        for step, (images, labels) in enumerate(train_loader):\n","            # check dim\n","            #print(images)\n","            #print(labels)\n","            if args.cuda:\n","                images = images.cuda()\n","                labels = labels.cuda()\n","            inputs = Variable(images)\n","            targets = Variable(labels)\n","            outputs = model(inputs)\n","            # refresh gradient before backprop\n","            optimizer.zero_grad()\n","            # print(targets[:, 0].shape)\n","            # print(outputs.shape)\n","            loss = criterion(outputs, targets[:, 0])\n","            loss.backward()\n","            optimizer.step()\n","\n","            #epoch_loss.append(loss.data[0])\n","            epoch_loss.append(loss.item())\n","            if (args.steps_loss > 0) and (step % args.steps_loss == 0):\n","                # print loss\n","                average = sum(epoch_loss) / len(epoch_loss)\n","                print(f'loss: {average} (epoch {epoch}, step {step})')\n","\n","                # check for early stop\n","                if early_stop(use_cuda=args.cuda, output=outputs, target=targets[:, 0], metric=\"iou\", threshold=0.8):\n","                    # if we can stop early, save model and exit\n","                    print(\"Early stopping score exceeded threshold... saving model and ending training stage\")\n","                    if args.attention:\n","                        filename = f'AttentionUNet-EarlyStop-{epoch:03}-{step:04}.pth'\n","                    else:\n","                        filename = f'UNet-EarlyStop-{epoch:03}-{step:04}.pth'\n","                    torch.save(model.state_dict(), filename)\n","                    return\n","            if (args.steps_save > 0) and (step % args.steps_save == 0):\n","                if args.attention:\n","                    filename = f'AttentionUNet-{epoch:03}-{step:04}.pth'\n","                else:\n","                    filename = f'UNet-{epoch:03}-{step:04}.pth'\n","                torch.save(model.state_dict(), filename)\n","                print(f'save: {filename} (epoch: {epoch}, step: {step})')\n","\n","                # show images and how it's going so far\n","                # print('Image shape of trainloader : ', end='')\n","                # print(images.shape)\n","                # print('Label shape of train_loader : ', end='')\n","                # print(labels.shape)\n","                #print('Output shape of train_loader : ', end='')\n","                #print(outputs.shape)\n","                _, outputs = torch.max(outputs, dim=1)\n","                #print(outputs.shape)\n","                outputs = outputs.unsqueeze(1)\n","                #print(outputs.shape)\n","                # show images\n","                plt.subplot(211)\n","                plt.imshow(make_grid(images.cpu()).permute(1,2,0).numpy())\n","                plt.axis('off')\n","                plt.title('Images')\n","                # print labels\n","                plt.subplot(212)\n","                outputs = outputs.cpu().numpy()[:, :, :, :, np.newaxis]\n","                color_Label = np.dot(outputs == 0, cmap[0])\n","                for i in range(1, cmap.shape[0]):\n","                    color_Label += np.dot(outputs == i, cmap[i])\n","                color_Label = color_Label.swapaxes(1,4)\n","                plt.imshow((make_grid(torch.tensor(color_Label.squeeze())).permute(1,2,0).numpy()).astype('uint8'))\n","                plt.axis('off')\n","                plt.title('Label')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jLVPfKH2BoLy","colab_type":"text"},"source":["## evaluation"]},{"cell_type":"code","metadata":{"id":"TrPBkTbXBmfL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593998466315,"user_tz":-540,"elapsed":800,"user":{"displayName":"Jinha Chung","photoUrl":"","userId":"09027664932398115600"}}},"source":["def evaluate(args, model):\n","    # set model to evaluation mode\n","    model.eval()\n","\n","    image = input_transform(Image.open(args.image))\n","    label = model(Variable(image, volatile=True).unsqueeze(0))\n","    label = color_transform(label[0].data.max(0)[1])\n","\n","    image_transform(label).save(args.label)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OVsOTk5xpDKM","colab_type":"text"},"source":["## main function\n"]},{"cell_type":"code","metadata":{"id":"-hjPXDR7pEff","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593998469260,"user_tz":-540,"elapsed":836,"user":{"displayName":"Jinha Chung","photoUrl":"","userId":"09027664932398115600"}}},"source":["def main(args):\n","    # load correct model\n","    if args.attention == True:\n","        model = unet.AttentionUnet(in_channels=NUM_CHANNELS,out_channels=NUM_CLASSES)\n","    elif args.attention == False:\n","        # we don't use residual for non-denoising purposes\n","        model = unet.Unet(in_channels=NUM_CHANNELS,out_channels=NUM_CLASSES)\n","    # check if we use GPU\n","    if args.cuda:\n","        model = model.cuda()\n","    # check for mode - training or evaluation?\n","    if args.mode == 'eval':\n","        evaluate(args, model)\n","    elif args.mode == 'train':\n","        train(args, model)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WICCzALEwqX1","colab_type":"text"},"source":["## actual running\n","the basic structure of this snippet is also from [provided link](https://github.com/bodokaiser/piwise)"]},{"cell_type":"code","metadata":{"id":"QB9tSNVEwsPd","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    # comment out lines from original code that is not used here\n","    parser = ArgumentParser()\n","    parser.add_argument('--cuda', action='store_true')\n","    parser.add_argument('--attention', action='store_true')\n","    #parser.add_argument('--state')\n","\n","    subparsers = parser.add_subparsers(dest='mode')\n","    subparsers.required = True\n","\n","    parser_eval = subparsers.add_parser('eval')\n","    parser_eval.add_argument('image')\n","    parser_eval.add_argument('label')\n","\n","    parser_train = subparsers.add_parser('train')\n","    #parser_train.add_argument('--port', type=int, default=80)\n","    parser_train.add_argument('--datadir', required=True)\n","    parser_train.add_argument('--num-epochs', type=int, default=32)\n","    parser_train.add_argument('--num-workers', type=int, default=4)\n","    parser_train.add_argument('--batch-size', type=int, default=1)\n","    parser_train.add_argument('--steps-loss', type=int, default=50)\n","    #parser_train.add_argument('--steps-plot', type=int, default=0)\n","    parser_train.add_argument('--steps-save', type=int, default=500)\n","    # since we can't pass CLI arugments in Python notebook,\n","    # assign variables manually\n","    # add two spaces between each chunk so that the data directory doesn't get split\n","    command_line = \"--cuda  train  --datadir  gdrive/My Drive/Project/data  --num-epochs  320  --num-workers  4  --batch-size  4  --steps-save  500\"\n","    args = parser.parse_args(command_line.split(\"  \"))\n","    print(args)\n","    main(args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YOtyiiBKXGDh","colab_type":"code","colab":{}},"source":["!ls sample_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jY7rEi0dXcvI","colab_type":"code","colab":{}},"source":["!cp UNet-064-0500.pth \"gdrive/My Drive/Project/models/UNetWithoutResPath-64epoch-1590.pth\""],"execution_count":null,"outputs":[]}]}